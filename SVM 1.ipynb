{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Wisconsin (Diagnostic) Database\n",
      "=============================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "References\n",
      "----------\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cancer['DESCR']) # Description about dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame(cancer['data'], columns=cancer['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      "mean radius                569 non-null float64\n",
      "mean texture               569 non-null float64\n",
      "mean perimeter             569 non-null float64\n",
      "mean area                  569 non-null float64\n",
      "mean smoothness            569 non-null float64\n",
      "mean compactness           569 non-null float64\n",
      "mean concavity             569 non-null float64\n",
      "mean concave points        569 non-null float64\n",
      "mean symmetry              569 non-null float64\n",
      "mean fractal dimension     569 non-null float64\n",
      "radius error               569 non-null float64\n",
      "texture error              569 non-null float64\n",
      "perimeter error            569 non-null float64\n",
      "area error                 569 non-null float64\n",
      "smoothness error           569 non-null float64\n",
      "compactness error          569 non-null float64\n",
      "concavity error            569 non-null float64\n",
      "concave points error       569 non-null float64\n",
      "symmetry error             569 non-null float64\n",
      "fractal dimension error    569 non-null float64\n",
      "worst radius               569 non-null float64\n",
      "worst texture              569 non-null float64\n",
      "worst perimeter            569 non-null float64\n",
      "worst area                 569 non-null float64\n",
      "worst smoothness           569 non-null float64\n",
      "worst compactness          569 non-null float64\n",
      "worst concavity            569 non-null float64\n",
      "worst concave points       569 non-null float64\n",
      "worst symmetry             569 non-null float64\n",
      "worst fractal dimension    569 non-null float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_feat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_feat\n",
    "y = cancer['target']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "# C - It controls the misclassification on the training data. A large C value gives us low bias and high variance\n",
    "# low bias because we penalize the data for misclassification alot,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C and Gamma are the parameters for a nonlinear support vector machine (SVM) with a Gaussian radial basis function kernel.**\n",
    "**C is the parameter for the soft margin cost function, which controls the influence of each individual support vector; this process involves trading error penalty for stability.**\n",
    "**If gamma is large, then variance is small implying the support vector does not have wide-spread influence. Technically speaking, large gamma leads to high bias and low variance models, and vice-versa.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions =model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  71]\n",
      " [  0 117]] \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        71\n",
      "          1       0.62      1.00      0.77       117\n",
      "\n",
      "avg / total       0.39      0.62      0.48       188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sg\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions), '\\n', classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples**\n",
    "\n",
    "    Basically it predicted everything to class 1\n",
    "    This is happening because a model needs to have its parameters adjusted, and it may also help to normalizing data as well when we are passing it into SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# It takes a dictionary that describes the parameters to be tried and model to be trained.\n",
    "# Grid of parameters found to be dictionary, where the keys are the parameters and values is basically list of settings to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[0.1,1,10,100,1000], 'gamma':[1,0.1,0.01,0.001,0.0001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SVC(), param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......................... C=0.1, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......................... C=0.1, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......................... C=0.1, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....................... C=0.1, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....................... C=0.1, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....................... C=0.1, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...................... C=0.1, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...................... C=0.1, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...................... C=0.1, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ..................... C=0.1, gamma=0.001, score=0.629921 -   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ..................... C=0.1, gamma=0.001, score=0.629921 -   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ..................... C=0.1, gamma=0.001, score=0.629921 -   0.0s\n",
      "[CV] C=0.1, gamma=0.0001 .............................................\n",
      "[CV] .................... C=0.1, gamma=0.0001, score=0.905512 -   0.0s\n",
      "[CV] C=0.1, gamma=0.0001 .............................................\n",
      "[CV] .................... C=0.1, gamma=0.0001, score=0.944882 -   0.0s\n",
      "[CV] C=0.1, gamma=0.0001 .............................................\n",
      "[CV] .................... C=0.1, gamma=0.0001, score=0.921260 -   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................... C=1, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........................... C=1, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........................... C=1, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......................... C=1, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......................... C=1, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......................... C=1, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........................ C=1, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........................ C=1, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........................ C=1, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....................... C=1, gamma=0.001, score=0.913386 -   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....................... C=1, gamma=0.001, score=0.929134 -   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....................... C=1, gamma=0.001, score=0.960630 -   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ...................... C=1, gamma=0.0001, score=0.944882 -   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ...................... C=1, gamma=0.0001, score=0.960630 -   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ...................... C=1, gamma=0.0001, score=0.960630 -   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......................... C=10, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......................... C=10, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......................... C=10, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........................ C=10, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........................ C=10, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........................ C=10, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....................... C=10, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....................... C=10, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....................... C=10, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...................... C=10, gamma=0.001, score=0.905512 -   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...................... C=10, gamma=0.001, score=0.921260 -   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...................... C=10, gamma=0.001, score=0.937008 -   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ..................... C=10, gamma=0.0001, score=0.937008 -   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ..................... C=10, gamma=0.0001, score=0.960630 -   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ..................... C=10, gamma=0.0001, score=0.952756 -   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......................... C=100, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......................... C=100, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......................... C=100, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....................... C=100, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....................... C=100, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....................... C=100, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...................... C=100, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...................... C=100, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...................... C=100, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ..................... C=100, gamma=0.001, score=0.905512 -   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ..................... C=100, gamma=0.001, score=0.921260 -   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ..................... C=100, gamma=0.001, score=0.937008 -   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .................... C=100, gamma=0.0001, score=0.921260 -   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .................... C=100, gamma=0.0001, score=0.960630 -   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .................... C=100, gamma=0.0001, score=0.952756 -   0.0s\n",
      "[CV] C=1000, gamma=1 .................................................\n",
      "[CV] ........................ C=1000, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=1000, gamma=1 .................................................\n",
      "[CV] ........................ C=1000, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=1000, gamma=1 .................................................\n",
      "[CV] ........................ C=1000, gamma=1, score=0.629921 -   0.0s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ...................... C=1000, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ...................... C=1000, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ...................... C=1000, gamma=0.1, score=0.629921 -   0.0s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] ..................... C=1000, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] ..................... C=1000, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] ..................... C=1000, gamma=0.01, score=0.629921 -   0.0s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .................... C=1000, gamma=0.001, score=0.905512 -   0.0s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .................... C=1000, gamma=0.001, score=0.921260 -   0.0s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .................... C=1000, gamma=0.001, score=0.937008 -   0.0s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ................... C=1000, gamma=0.0001, score=0.913386 -   0.0s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ................... C=1000, gamma=0.0001, score=0.960630 -   0.0s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ................... C=1000, gamma=0.0001, score=0.944882 -   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.0001}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 63   8]\n",
      " [  4 113]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.89      0.91        71\n",
      "          1       0.93      0.97      0.95       117\n",
      "\n",
      "avg / total       0.94      0.94      0.94       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, grid_predictions))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-validation** is when you reserve part of your data to use in evaluating your model. There are different cross-validation methods. The simplest conceptually is to just take 70% (just making up a number here, it doesn't have to be 70%) of your data and use that for training, and then use the remaining 30% of the data to evaluate the model's performance. The reason you need different data for training and evaluating the model is to protect against overfitting. There are other (slightly more involved) cross-validation techniques, of course, like k-fold cross-validation, which often used in practice.\n",
    "\n",
    "**Grid search** is a method to perform hyper-parameter optimisation, that is, it is a method to find the best combination of hyper-parameters (an example of an hyper-parameter is the learning rate of the optimiser), for a given model (e.g. a CNN) and test dataset. In this scenario, you have several models, each with a different combination of hyper-parameters. Each of these combinations of parameters, which correspond to a single model, can be said to lie on a point of a \"grid\". The goal is then to train each of these models and evaluate them e.g. using cross-validation. You then select the one that performed best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
